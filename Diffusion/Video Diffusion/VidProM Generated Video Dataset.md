---
Date: 2024-06-15
Title: VidProM
dg-publish: true
tags:
  - Diffusion
  - Dataset
---

# 1 Introduction

1.67 million unique text-to-video prompts 
6.69 million videos generated by 4 diffusion video models 
## 1.1 Problem Statement

就一个问题： 没有足够大的公开的文生视频的数据集。 

text2video不能完全直接利用text2image的提示词。 

> 这一点在本人的实验中也有一些发现


## 1.2 Stated Contribution

1. 提出了一个公开的专门针对video prompt研究的大规模数据集
2. 研究了text2video的prompt数据集的必要性
3. 启发后来工作的研究方向

# 2 Related Work

## 2.1 text-to-video diffusion models 
Pika VideoCrafter2 Modelscope etc. 

## 2.2 Existing Datasets
现在公开的文生视频数据集用真实视频的多，用生成数据的少。 WebVid-10M 和 HDVILA-100M，Panda70M等等。 


> 近些月来，生成式数据集得到了广泛的应用，但是其带来增益的原因我想可以好好探索。 

目前的数据集都低估了prompt数据集的重要性。 PromptSource认为用prompt来训练和提问大模型可以有更加高效的结果。 DiffusionDB手机了大量的prompt-image dataset来启发新的研究。 

用一个DiscordChatExporter手机了一段时间内

# 3 Method

# 4 Experiment
## 4.1 Implementation Details  

# 5 Summary

# 6 Comments

